{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "638a009e",
   "metadata": {},
   "source": [
    "# Logistic Regression Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3264bd3e",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. What is Logistic Regression, and how does it differ from Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da5bbd1",
   "metadata": {},
   "source": [
    "**Logistic Regression** is a supervised learning algorithm used for **classification tasks**, especially binary classification (e.g., spam/not spam, pass/fail).\n",
    "* **Purpose:** It predicts the **probability** that an instance belongs to a particular class.\n",
    "* **Output:** Produces values between 0 and 1 by using the **sigmoid (logistic) function** on the linear combination of input features.\n",
    "\n",
    "**Mathematical form:**\n",
    "\n",
    "$$\n",
    "p = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_n x_n)}}\n",
    "$$\n",
    "\n",
    "Where $p$ is the probability of belonging to the positive class.\n",
    "\n",
    "**How it differs from Linear Regression?**\n",
    "\n",
    "| Feature                     | Linear Regression                               | Logistic Regression                                             |\n",
    "| --------------------------- | ----------------------------------------------- | --------------------------------------------------------------- |\n",
    "| **Goal**                    | Predicts continuous numerical values            | Predicts probability for classification                         |\n",
    "| **Output range**            | Any real number (-∞ to +∞)                      | Between 0 and 1 (via sigmoid/logistic function)                 |\n",
    "| **Algorithm type**          | Regression                                      | Classification                                                  |\n",
    "| **Error metric**            | Uses **Mean Squared Error (MSE)**               | Uses **Log-Loss (Cross-Entropy Loss)**                          |\n",
    "| **Decision boundary**       | Not applicable                                  | Classification threshold (commonly 0.5)                         |\n",
    "| **Relationship assumption** | Linear relationship between features and output | Linear relationship between features and **log-odds** of output |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39f787a",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Explain the role of the Sigmoid function in Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a0fed",
   "metadata": {},
   "source": [
    "1. **Purpose**\n",
    "\n",
    "   * In logistic regression, the model first computes a **linear combination** of input features:\n",
    "\n",
    "     $$\n",
    "     z = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_nx_n\n",
    "     $$\n",
    "\n",
    "     This $z$ can take any value from $-\\infty$ to $+\\infty$.\n",
    "   * The **sigmoid function** is applied to transform this unbounded value into a **probability** in the range **(0, 1)**.\n",
    "\n",
    "2. **Sigmoid Function Formula**\n",
    "\n",
    "   $$\n",
    "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "   $$\n",
    "\n",
    "   * When $z \\to +\\infty$, $\\sigma(z) \\to 1$\n",
    "   * When $z \\to -\\infty$, $\\sigma(z) \\to 0$\n",
    "   * When $z = 0$, $\\sigma(z) = 0.5$\n",
    "\n",
    "3. **Why It’s Important in Logistic Regression**\n",
    "\n",
    "   * **Probability Mapping:** Converts linear output into probabilities for classification.\n",
    "   * **Interpretability:** The output can be interpreted as “probability of belonging to the positive class.”\n",
    "   * **Decision Making:** By setting a threshold (commonly 0.5), we classify the data into two classes.\n",
    "   * **Smooth Gradient:** The function is differentiable, which allows optimization using **Gradient Descent**.\n",
    "\n",
    "4. **Visualization Insight**\n",
    "\n",
    "   * The sigmoid curve is **S-shaped**, ensuring that extremely large or small linear scores don’t cause extreme instability—values saturate near 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b710b4",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. What is Regularization in Logistic Regression and why is it needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d812b",
   "metadata": {},
   "source": [
    "Regularization is a technique used to **prevent overfitting** by adding a **penalty term** to the cost function in logistic regression.\n",
    "It discourages the model from fitting too closely to the training data by **shrinking the coefficients** ($\\beta$ values).\n",
    "\n",
    "### **Why It’s Needed**\n",
    "\n",
    "1. **Overfitting Control**\n",
    "\n",
    "   * Without regularization, logistic regression can produce very large weights for some features, especially if the dataset has many features or multicollinearity.\n",
    "   * Large weights can cause the model to fit training data noise, reducing generalization to new data.\n",
    "\n",
    "2. **Feature Selection**\n",
    "\n",
    "   * Certain regularization methods (like **L1 regularization**) can force some coefficients to become exactly zero, effectively removing irrelevant features.\n",
    "\n",
    "3. **Improved Generalization**\n",
    "\n",
    "   * By constraining weights, the model becomes simpler and less sensitive to fluctuations in training data.\n",
    "\n",
    "### **Types of Regularization in Logistic Regression**\n",
    "\n",
    "| Type            | Penalty Term Added to Cost Function | Effect                                                             |                                                               \n",
    "| --------------- | ----------------------------------- | ------------------------------------------------------------------ |\n",
    "| **L1 (Lasso)**  | $\\frac{\\lambda}{m} \\sum_{j=1}^n \\lvert\\beta_j\\rvert$  | Shrinks some coefficients to exactly zero → **feature selection** |\n",
    "| **L2 (Ridge)**  | $\\frac{\\lambda}{2m} \\sum_{j=1}^n \\beta_j^2$  | Shrinks coefficients evenly, no zeroing out → **better stability** |   \n",
    "| **Elastic Net** | Combination of L1 and L2            | Balances between feature selection and stability                   |\n",
    "\n",
    "**Without regularization**:\n",
    "\n",
    "$$\n",
    "J(\\beta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y^{(i)} \\log h_\\beta(x^{(i)}) + (1 - y^{(i)}) \\log(1 - h_\\beta(x^{(i)})) \\right]\n",
    "$$\n",
    "\n",
    "#### **L2 Regularization (Ridge Logistic Regression)**\n",
    "\n",
    "With **L2 penalty**:\n",
    "\n",
    "$$\n",
    "J_{L2}(\\beta) = J(\\beta) + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\beta_j^2\n",
    "$$\n",
    "\n",
    "* **Penalty term:** $\\frac{\\lambda}{2m} \\sum_{j=1}^n \\beta_j^2$\n",
    "* **Effect:** Shrinks coefficients towards zero but **does not** make them exactly zero.\n",
    "\n",
    "#### **L1 Regularization (Lasso Logistic Regression)**\n",
    "\n",
    "With **L1 penalty**:\n",
    "\n",
    "$$\n",
    "J_{L1}(\\beta) = J(\\beta) + \\frac{\\lambda}{m} \\sum_{j=1}^n |\\beta_j|\n",
    "$$\n",
    "\n",
    "* **Penalty term:** $\\frac{\\lambda}{m} \\sum_{j=1}^n |\\beta_j|$\n",
    "* **Effect:** Can make some coefficients **exactly zero**, performing **automatic feature selection**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c0d09",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. What are some common evaluation metrics for classification models, and why are they important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb0b710",
   "metadata": {},
   "source": [
    "Evaluation metrics help measure **how well** a classification model performs.\n",
    "They are important because accuracy alone can be misleading — especially with **imbalanced datasets**.\n",
    "\n",
    "### **1. Accuracy**\n",
    "\n",
    "* **Formula:**\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{Total Samples}}\n",
    "$$\n",
    "\n",
    "* **Meaning:** Percentage of correct predictions.\n",
    "* **Limitation:** Can be misleading if classes are imbalanced (e.g., 95% accuracy by predicting all samples as the majority class).\n",
    "\n",
    "### **2. Precision**\n",
    "\n",
    "* **Formula:**\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "* **Meaning:** Out of all predicted positives, how many were actually positive.\n",
    "* **Importance:** High precision means fewer false alarms — useful in cases like spam detection.\n",
    "\n",
    "### **3. Recall (Sensitivity / True Positive Rate)**\n",
    "\n",
    "* **Formula:**\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "* **Meaning:** Out of all actual positives, how many were correctly predicted.\n",
    "* **Importance:** High recall means fewer missed positive cases — critical in medical diagnoses.\n",
    "\n",
    "### **4. F1-Score**\n",
    "\n",
    "* **Formula:**\n",
    "\n",
    "$$\n",
    "F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "* **Meaning:** Harmonic mean of Precision and Recall.\n",
    "* **Importance:** Good for imbalanced datasets when both precision and recall matter.\n",
    "\n",
    "### **5. ROC-AUC (Receiver Operating Characteristic – Area Under Curve)**\n",
    "\n",
    "* **Meaning:** Measures the trade-off between True Positive Rate (Recall) and False Positive Rate across different thresholds.\n",
    "* **Importance:** AUC close to 1 indicates strong model discrimination ability.\n",
    "\n",
    "### **6. Confusion Matrix**\n",
    "\n",
    "* **Meaning:** A table showing counts of TP, TN, FP, FN.\n",
    "* **Importance:** Gives a complete picture of classification performance, not just one score.\n",
    "\n",
    "✅ **Why these metrics are important:**\n",
    "\n",
    "* They allow you to **choose the right model** for the problem.\n",
    "* Different problems need **different priorities** (e.g., Precision for fraud detection, Recall for cancer screening).\n",
    "* They help detect **overfitting** and **imbalanced class bias**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8122ca5",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bfe7a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "\n",
      "Logistic Regression Model Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Load dataset from sklearn (Iris dataset for example)\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create a Pandas DataFrame from the dataset\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Features (X) and Target (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression(max_iter=200)  # Increase max_iter to ensure convergence\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nLogistic Regression Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e721666",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "363a0acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients (per feature, per class):\n",
      "[[-0.39348375  0.96248072 -2.37513667 -0.99874733]\n",
      " [ 0.50844947 -0.25480597 -0.21300937 -0.77574588]\n",
      " [-0.11496571 -0.70767474  2.58814604  1.77449321]]\n",
      "\n",
      "Intercepts for each class:\n",
      "[  9.00911397   1.86887848 -10.87799245]\n",
      "\n",
      "L2-Regularized Logistic Regression Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from sklearn (Iris dataset for example)\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create a Pandas DataFrame from the dataset\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Features (X) and Target (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize Logistic Regression model with L2 regularization\n",
    "model = LogisticRegression(\n",
    "    penalty='l2',       # L2 Regularization\n",
    "    C=1.0,              # Regularization strength (smaller value = stronger regularization)\n",
    "    max_iter=200        # Increase iterations for convergence\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print model coefficients and accuracy\n",
    "print(\"Model Coefficients (per feature, per class):\")\n",
    "print(model.coef_)\n",
    "print(\"\\nIntercepts for each class:\")\n",
    "print(model.intercept_)\n",
    "print(f\"\\nL2-Regularized Logistic Regression Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d18958",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Write a Python program to train a Logistic Regression model for multiclass classification using `multi_class='ovr'` and print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b518b6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (One-vs-Rest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.89      0.94         9\n",
      "   virginica       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset from sklearn (Iris dataset for example)\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create a Pandas DataFrame from the dataset\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Features (X) and Target (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize Logistic Regression model with One-vs-Rest strategy\n",
    "model = LogisticRegression(\n",
    "    multi_class='ovr',   # One-vs-Rest classification\n",
    "    max_iter=200,        # Increase iterations for convergence\n",
    "    solver='lbfgs'       # Suitable for small datasets like Iris\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report (One-vs-Rest):\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ab17b",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2f365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 10, 'penalty': 'l1'}\n",
      "Best Cross-Validation Accuracy: 0.9583\n",
      "Test Accuracy with Best Parameters: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load dataset from sklearn (Iris dataset)\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=500, solver='liblinear')\n",
    "# Using 'liblinear' because it supports both L1 and L2 penalties\n",
    "\n",
    "# Define the parameter grid for C and penalty\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],   # Regularization strength (inverse)\n",
    "    'penalty': ['l1', 'l2']         # L1 = Lasso, L2 = Ridge\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,             # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Make predictions using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Best Cross-Validation Accuracy: {best_score:.4f}\")\n",
    "print(f\"Test Accuracy with Best Parameters: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b986a9e",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c3d190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without Scaling: 1.0000\n",
      "Accuracy with Scaling:    1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset from sklearn (Iris dataset)\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Without Scaling\n",
    "model_no_scaling = LogisticRegression(max_iter=200)\n",
    "model_no_scaling.fit(X_train, y_train)\n",
    "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
    "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
    "\n",
    "# With Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model_with_scaling = LogisticRegression(max_iter=200)\n",
    "model_with_scaling.fit(X_train_scaled, y_train)\n",
    "y_pred_with_scaling = model_with_scaling.predict(X_test_scaled)\n",
    "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
    "\n",
    "# Results\n",
    "print(f\"Accuracy without Scaling: {accuracy_no_scaling:.4f}\")\n",
    "print(f\"Accuracy with Scaling:    {accuracy_with_scaling:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e6f75",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b427c7",
   "metadata": {},
   "source": [
    "We want to predict which customers will respond to a marketing campaign.\n",
    "**Challenge:**\n",
    "\n",
    "* **Imbalanced dataset** → Only **5% positive class** (responders).\n",
    "* If we use standard accuracy, predicting everyone as “No” would give \\~95% accuracy but be useless for business.\n",
    "\n",
    "### **1. Data Understanding & Preprocessing**\n",
    "\n",
    "* **Exploratory Data Analysis (EDA):**\n",
    "\n",
    "  * Check class distribution → confirm imbalance.\n",
    "  * Look for missing values, duplicates, outliers.\n",
    "  * Understand feature types (numeric, categorical, date).\n",
    "* **Feature Engineering:**\n",
    "\n",
    "  * Extract meaningful features (e.g., recency of purchase, frequency, total spend).\n",
    "  * Convert categorical variables → **One-Hot Encoding** or **Target Encoding**.\n",
    "  * Handle missing values with imputation (mean/median for numeric, mode/most frequent for categorical).\n",
    "\n",
    "### **2. Feature Scaling**\n",
    "\n",
    "* Logistic Regression is sensitive to feature scales.\n",
    "* Use **StandardScaler** (mean = 0, variance = 1) **after** splitting train/test data to avoid leakage.\n",
    "\n",
    "### **3. Handling Class Imbalance**\n",
    "\n",
    "We can combine several techniques:\n",
    "\n",
    "1. **Class Weight Adjustment:**\n",
    "\n",
    "   * Use `class_weight='balanced'` in Logistic Regression.\n",
    "   * This adjusts weights inversely proportional to class frequencies.\n",
    "2. **Oversampling Minority Class:**\n",
    "\n",
    "   * Use **SMOTE** (Synthetic Minority Over-sampling Technique) to generate synthetic responders.\n",
    "3. **Undersampling Majority Class:**\n",
    "\n",
    "   * Randomly remove some \"non-responders\" to balance faster, but risk losing information.\n",
    "4. **Combination Approach:**\n",
    "\n",
    "   * Light undersampling + SMOTE to keep dataset size manageable.\n",
    "\n",
    "### **4. Train/Test Split**\n",
    "\n",
    "* **Stratified Split** to preserve class ratio in both sets.\n",
    "* Common: 70–80% training, 20–30% testing.\n",
    "\n",
    "### **5. Model Training with Hyperparameter Tuning**\n",
    "\n",
    "* Use **GridSearchCV** or **RandomizedSearchCV** with **StratifiedKFold CV** to tune:\n",
    "\n",
    "  * `C` (inverse regularization strength)\n",
    "  * `penalty` (L1, L2, Elastic Net)\n",
    "  * `solver` (liblinear, saga depending on penalty)\n",
    "* Example parameter grid:\n",
    "\n",
    "  ```python\n",
    "  param_grid = {\n",
    "      'C': [0.01, 0.1, 1, 10],\n",
    "      'penalty': ['l1', 'l2'],\n",
    "      'solver': ['liblinear', 'saga']\n",
    "  }\n",
    "  ```\n",
    "\n",
    "### **6. Model Evaluation**\n",
    "\n",
    "* **Avoid plain accuracy** — use metrics that handle imbalance:\n",
    "\n",
    "  * **Precision**: Of predicted responders, how many actually respond? (Important to avoid spamming uninterested customers)\n",
    "  * **Recall (Sensitivity)**: Of all actual responders, how many did we correctly identify? (Important for campaign reach)\n",
    "  * **F1-score**: Harmonic mean of Precision & Recall.\n",
    "  * **ROC-AUC**: Overall ability to rank responders higher than non-responders.\n",
    "  * **PR-AUC** (Precision-Recall AUC): More informative for highly imbalanced datasets.\n",
    "* For business context:\n",
    "\n",
    "  * High **Recall** ensures we target as many potential responders as possible.\n",
    "  * High **Precision** keeps campaign cost low by reducing wasted outreach.\n",
    "\n",
    "### **7. Business-Aware Decision Threshold**\n",
    "\n",
    "* Logistic Regression outputs probabilities → default threshold is 0.5.\n",
    "* In imbalanced cases, **lower the threshold** (e.g., 0.3) to capture more positives (increase recall).\n",
    "* Select threshold based on business trade-off between:\n",
    "\n",
    "  * **Marketing Cost** (false positives)\n",
    "  * **Lost Revenue** (false negatives)\n",
    "\n",
    "### **8. Final Deployment & Monitoring**\n",
    "\n",
    "* Retrain periodically as customer behavior changes.\n",
    "* Monitor:\n",
    "\n",
    "  * Data drift (feature distributions changing over time)\n",
    "  * Model drift (accuracy degradation)\n",
    "  * Business KPIs (ROI of marketing campaigns)\n",
    "\n",
    "✅ **Summary Table of Approach:**\n",
    "\n",
    "| Step                    | Technique Used                                           |\n",
    "| ----------------------- | -------------------------------------------------------- |\n",
    "| Data cleaning           | Missing value imputation, encoding categorical variables |\n",
    "| Feature scaling         | StandardScaler                                           |\n",
    "| Handling imbalance      | Class weights, SMOTE, undersampling                      |\n",
    "| Model selection         | Logistic Regression                                      |\n",
    "| Hyperparameter tuning   | GridSearchCV with StratifiedKFold                        |\n",
    "| Evaluation metrics      | Precision, Recall, F1, ROC-AUC, PR-AUC                   |\n",
    "| Threshold adjustment    | Based on cost-benefit analysis                           |\n",
    "| Deployment & monitoring | Retraining & KPI tracking                                |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
